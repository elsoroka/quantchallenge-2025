{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b572f3e",
   "metadata": {},
   "source": [
    "# Getting Started: Market Research\n",
    "This Jupyter notebook is a quick demonstration on how to get started on the market research section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9a964a",
   "metadata": {},
   "source": [
    "## 1) Download Data\n",
    "Please download the train and test data and place it within the ./research/data path. If you've placed it in the correct place, you should see the following cell work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "new_cols_train = pd.read_csv('./data/train_new.csv')\n",
    "train_data = pd.concat([train_data, new_cols_train], axis=1)\n",
    "\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "new_cols_test = pd.read_csv('./data/test_new.csv')\n",
    "test_data = pd.concat([test_data, new_cols_test], axis=1)\n",
    "\n",
    "\n",
    "X_cols = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n",
    "y_cols = ['Y1', 'Y2']\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9a46a",
   "metadata": {},
   "source": [
    "## 2) Investigate the Dataset\n",
    "In the datasets, you're given columns of time and A through N, each of which represent some sort of real-life market quantity. In the train dataset, you're also given Y1 and Y2, real-life market quantities you'd like to predict in terms of time and A through N. You're not given Y1 and Y2 in the test set, because this is what you're being asked to predict.\n",
    "\n",
    "Let's do some exploration of the relationships of A - N and Y1. In particular, let's look at the relationship between C and Y1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66138f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,4))\n",
    "_ = ax1.hist(train_data['Y1'], bins=100)\n",
    "_ = ax2.hist(train_data['Y2'], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc87d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_data.mean(axis=0)\n",
    "std = train_data.std(axis=0)\n",
    "print(\"col, mean, std\")\n",
    "for _m, _std, col in zip(m, std, X_cols):\n",
    "    print(col, _m, _std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d58b3",
   "metadata": {},
   "source": [
    "## Emi's notes on this\n",
    "* The biggest problem with this data is the distribution of Y1 and Y2 is not normal. The goal is to maximize $R^2$, and the corresponding loss function is $\\ell_2$ but this produces a normal distribution of errors between $\\hat y$ and $y$. Ideally, Y1 and Y2 should have normal distributions but they do not. Maybe resampling them will help?\n",
    "\n",
    "* You should probably standardize the column mean and std because on inspection, column A is much larger than the others. (See following cell.)\n",
    "\n",
    "* There are NAN values in O and P that have been replaced with 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846116d2",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b619a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_data.fillna(0, inplace=True)\n",
    "\n",
    "Xtrain = train_data[X_cols]\n",
    "ytrain = train_data[y_cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtrain)\n",
    "print(scaler.mean_)\n",
    "\n",
    "Xtrain = scaler.transform(Xtrain)\n",
    "\n",
    "model = LinearRegression().fit(Xtrain, ytrain)\n",
    "print(\"Train:\", model.score(Xtrain, ytrain))\n",
    "\n",
    "print(\"col, Y1, Y2\")\n",
    "for c1, c2, col in zip(model.coef_[0,:], model.coef_[1,:], X_cols):\n",
    "    print(col, c1, c2)\n",
    "#Xtest = test_data[X_cols]\n",
    "#ytest = test_data[y_cols]\n",
    "\n",
    "#print(\"Test:\", model.score(Xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430010d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between C and Y1\n",
    "correlation = train_data['C'].corr(train_data['Y1'])\n",
    "print(f\"Correlation between C and Y1: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1edef",
   "metadata": {},
   "source": [
    "Clearly there's a strong relationship between C and Y1. You should definitely use C to predict Y1!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ba64a",
   "metadata": {},
   "source": [
    "## 3) Submit Predictions\n",
    "In order to submit predictions, we need to make a CSV file with three columns: id, Y1, and Y2. In the below example, we let our predictions of Y1 and Y2 be the means of Y1 and Y2 in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ed794",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test_data[['id']]\n",
    "preds['Y1'] = train_data['Y1'].mean()\n",
    "preds['Y2'] = train_data['Y2'].mean()\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d072d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preds to csv\n",
    "preds.to_csv('preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc988b0",
   "metadata": {},
   "source": [
    "You should now be able to submit preds.csv to [https://quantchallenge.org/dashboard/data/upload-predictions](https://quantchallenge.org/dashboard/data/upload-predictions)! Note that you should receive a public $R^2$ score of $-0.042456$ with this set of predictions. You should try to get the highest possible $R^2$ score over the course of these next few days. Be careful of overfitting to the public score, which is only calculated on a subset of the test dataâ€”the final score that counts is the private $R^2$ score!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
